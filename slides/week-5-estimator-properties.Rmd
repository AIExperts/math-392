---
title: "Week Five"
output: ioslides_presentation
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Install these packages first
knitr::opts_chunk$set(message = FALSE)
library(tidyverse)
library(readr)
library(knitr)
```

# Properties of Estimators

# Bias

## Simulate uniform data

We simulate a random sample of 20 Unif$(\alpha=0, \beta=30)$ IID uniform variables.

```{r}
n <- 20
x <- runif(n, min = 0, max = 30)
2 * mean(x)
```


## Full simulation

We simulate a many random samples of 20 Unif$(\alpha=0, \beta=30)$ IID uniform variables.

```{r}
it <- 1000
mom <- rep(NA, it)

for (i in 1:it) {
  n <- 20
  x <- runif(n, min = 0, max = 30)
  mom[i] <- 2 * mean(x)
}

df <- data.frame(mom)
mean_mom <- mean(mom)
```


## Sampling dist. {.smaller .build}

```{r}
library(tidyverse)
ggplot(df, aes(x = mom)) +
  geom_density(lwd = 1.2) +
  geom_vline(xintercept = mean_mom, col = "steelblue", lty = 2, lwd = 1.2)
```


## Full simulation

We also consider the MLE estimate.

```{r}
it <- 1000
mom <- rep(NA, it)
mle <- rep(NA, it)

for (i in 1:it) {
  n <- 20
  x <- runif(n, min = 0, max = 30)
  mom[i] <- 2 * mean(x)
  mle[i] <- max(x)
}

df <- data.frame(stat = c(mom, mle),
                 estimator = rep(c("MOM", "MLE"),
                                 times = c(it, it)))
mean_mom <- mean(mom)
mean_mle <- mean(mle)
```


## Sampling dist. {.smaller .build}

```{r}
ggplot(df, aes(x = stat, fill = estimator)) +
  geom_density(alpha = .3) +
  geom_vline(xintercept = mean_mom, col = "steelblue", lty = 2, lwd = 1.2) +
  geom_vline(xintercept = mean_mle, col = "tomato", lty = 2, lwd = 1.2)
```


# Bias correction

## Bias correction

```{r}
it <- 1000
mom <- rep(NA, it)
mle <- rep(NA, it)

for (i in 1:it) {
  n <- 20
  x <- runif(n, min = 0, max = 30)
  mom[i] <- 2 * mean(x)
  mle[i] <- ((n + 1) / n) * max(x)
}

df <- data.frame(stat = c(mom, mle),
                 estimator = rep(c("MOM", "MLE"),
                                 times = c(it, it)))
mean_mom <- mean(mom)
mean_mle <- mean(mle)
```


## Sampling dist. {.smaller .build}

```{r}
ggplot(df, aes(x = stat, fill = estimator)) +
  geom_density(alpha = .3) +
  geom_vline(xintercept = mean_mom, col = "steelblue", lty = 2, lwd = 1.2) +
  geom_vline(xintercept = mean_mle, col = "tomato", lty = 2, lwd = 1.2)
```


## Variances compared

```{r}
df %>%
  group_by(estimator) %>%
  summarize(var = var(stat))
```


# Consistency

## {.smaller .build}

We demonstrate the consistency of

$$
\hat{\beta}_{MLE} = \frac{n+1}{n} x_{max}
$$

```{r}
it <- 1000
n_vec <- c(20, 40, 80, 120, 200)
nsamps <- length(n_vec)
mle <- rep(NA, it * nsamps)

for (j in 1:nsamps) {
  for (i in 1:it) {
    n <- n_vec[j]
    x <- runif(n, min = 0, max = 30)
    mle[(j - 1) * it + i] <- ((n + 1) / n) * max(x)
}
}
df <- data.frame(stat = mle,
                 n = rep(n_vec, times = rep(it, nsamps)))
```


## {.build .smaller}

```{r echo = FALSE, eval = FALSE}
library(ggridges)
ggplot(df, aes(x = stat, y = as.factor(n))) +
  geom_density_ridges() +
  coord_flip() +
  geom_hline(yintercept = 30 - .3, lty = 3) +
  geom_hline(yintercept = 30 + .3, lty = 3) +
  ylab("n")
```

```{r}
ggplot(df, aes(x = n, y = stat)) +
  geom_point() +
  geom_hline(yintercept = 30 - .3, lty = 3) +
  geom_hline(yintercept = 30 + .3, lty = 3)
```


# Simulating from f

## I. Inverse transform method {.smaller .build}

$$
f(x;\theta) = 2x; \quad 0 < x < 1 \\
F(x;\theta) = x^2; \quad 0 < x < 1 \\
$$

```{r}
hist(sqrt(runif(1000)))
```


## Rejection sampling A {.smaller .build}

```{r}
n <- 1000
x <- runif(n)
u <- runif(n, min = 0, max = 2)
accept <- u < (2 * x)
hist(x[accept])
```


## Rejection sampling plot {.smaller .build}

```{r}
n <- 1000
x <- runif(n)
u <- runif(n, min = 0, max = 2)
library(tidyverse)
df <- data.frame(x = x, 
                 y = u, 
                 accept = u < (2 * x))
p <- ggplot(df, aes(x = x, y = y, col = accept)) +
  geom_point()
```


## Rejection sampling plot {.smaller .build}

```{r}
p
```


## Rejection sampling B {.smaller .build}

```{r}
n <- 1000
x <- runif(n)
accept <- rbinom(n, size = 1, prob = 2 * x/2)
hist(x[as.logical(accept)])
```



