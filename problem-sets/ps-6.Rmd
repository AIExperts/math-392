---
title: "MATH 392 Problem Set 6"
output: 
  github_document:
    fig_height: 3
    fig_width: 6
---


```{r, include=FALSE}
require(tidyverse) # load package
require(resampledata)
options(digits=4) # print 4 decimal places only
set.seed(1999) # set seed for reproducibility
```

### Macht

Imagine that you are one of the Allied commanders on the Western Front that is slowing advancing through France and scrawling down serial numbers from ruined and captured panzers as you go. Based on your expertise, you're confident that your current force of troops and tanks are sufficient to push far into Germany as long as the German force does not exceed 345 tanks.

Thus far, the serial numbers that have been captured are

```{r}
x <- c(47, 126, 285, 318, 142, 55, 231, 102, 
       164, 85, 242, 62, 289, 290)
```


#### Exercise 1.1

Conduct a hypothesis test using the bias-correct MLE for $\beta$ from a Uniform distribution to see if this data is consistent with a model where there are 345 tanks. Said another way, you are assessing two competing hypotheses regarding $\theta$ when assuming that the series numbers, $X$, follow a uniform distribution, $X \sim \textrm{Unif}(0, \theta)$. $H_0: \theta = 345 \quad \textrm{vs}. \quad H_A: \theta > 345$.

The test statistic that you will be using is $\hat{\theta}_{MLE, corr} = \frac{n + 1}{n} X_{max}$.


This is a setting where you are only interested in throwing out that model if the true number exceeds 345. Note that to perform the hypothesis test, you need to find the sampling distribution of the test statistic under the null hypothesis. We have seen several approaches to finding that distribution, including simulation, permutation, large sample theory, and exact analytical derivation.

```{r eval = FALSE, echo = FALSE}
beta_null <- 345
n <- length(x)
it <- 5000
beta_mles <- rep(NA, it)

for (i in 1:it) {
  x_sim <- sample(1:beta_null, size = n, replace = FALSE)
  beta_mles[i] <- (n + 1) / n * max(x_sim)
}
beta_obs <- (n + 1) / n * max(x)
hist(beta_mles)
mean(beta_mles > beta_obs)
```


#### Exercise 1.2

Conduct a second hypothesis test but this time use as your test statistic the method of moments estimator.

$$
\hat{\theta}_{MOM} = 2 \bar{X}
$$
```{r eval = FALSE, echo = FALSE}
beta_moms <- rep(NA, it)

for (i in 1:it) {
  x_sim <- sample(1:beta_null, size = n, replace = FALSE)
  beta_moms[i] <- 2 * mean(x_sim)
}
beta_obs <- 2 * mean(x)
hist(beta_moms)
mean(beta_moms > beta_obs)
```


#### Exercise 1.3

What type of errors are you succeptible to when making decisions using this framework? What are the associated costs of each one?


#### Exercise 1.4

It can be a bit unsettling when two methods of analyzing the same data set lead to different results. The notion of statistical power provides a metric for direct comparison between tests. Calculate the power of these tests in settings where the true parameter takes values of 325, 335, 345, 355, and 365, when taking samples of size $n = 17$. Create a plot of the resulting (point-wise) power curves. Which test statistic is preferred?

```{r eval = FALSE, echo = FALSE}
reject <- rep(NA, it)

for (j in 1:it) {
  x <- sample(1:345, size = n, replace = FALSE)
  beta_obs <- (n + 1) / n * max(x)
  for (i in 1:it) {
  x_sim <- sample(1:beta_null, size = n, replace = FALSE)
  beta_mles[i] <- (n + 1) / n * max(x_sim)
  }
  reject[j] <- mean(beta_mles > beta_obs) < .05
}
```